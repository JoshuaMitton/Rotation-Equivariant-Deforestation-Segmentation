{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe04b4e2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e5132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from skimage import filters\n",
    "\n",
    "from dataloader import ForestDataset\n",
    "from utils import get_train_weights, get_train_weights_binary\n",
    "from utils import get_acc_seg, get_acc_seg_weighted, get_acc_nzero, get_acc_class, get_acc_binseg\n",
    "from models import UNet\n",
    "from eq_models import UNet_eq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfab529",
   "metadata": {},
   "source": [
    "## Parameters which should be the same as those used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade2c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = f'UNET_eq_code_test'\n",
    "load_epoch = 10\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "device = 'cuda'\n",
    "model = 'unet_eq'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cce8b0",
   "metadata": {},
   "source": [
    "## Create datasets, dataloaders and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d68e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ForestDataset(csv_file='ForestNetDataset/train.csv',\n",
    "                                    root_dir='ForestNetDataset')\n",
    "val_dataset = ForestDataset(csv_file='ForestNetDataset/val.csv',\n",
    "                                    root_dir='ForestNetDataset')\n",
    "test_dataset = ForestDataset(csv_file='ForestNetDataset/test.csv',\n",
    "                                    root_dir='ForestNetDataset')\n",
    "\n",
    "## Get weights for re-weighting optimisation due to inbalance in dataset\n",
    "train_weights = get_train_weights(train_dataset)\n",
    "train_weights_bin_seg = get_train_weights_binary(train_dataset)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "if model == 'unet':\n",
    "    net = UNet(3, 1)\n",
    "elif model == 'unet_eq':\n",
    "    net = UNet_eq(3, 1)\n",
    "net = net.to(device)\n",
    "\n",
    "train_weights = torch.from_numpy(train_weights).type(torch.float).to(device)\n",
    "criterion_class = nn.CrossEntropyLoss(weight=train_weights)\n",
    "criterion_seg = nn.BCEWithLogitsLoss(pos_weight=train_weights_bin_seg.to(device))\n",
    "\n",
    "optimizer = optim.AdamW(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c368468",
   "metadata": {},
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train()\n",
    "net.eval()\n",
    "\n",
    "checkpoint = torch.load(f'Outputs/{savedir}/model_{load_epoch}.pt')\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac744a",
   "metadata": {},
   "source": [
    "## Plot the loss and accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da5c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = np.loadtxt(open(f'Outputs/{savedir}/training.txt', 'r'), delimiter=' ', dtype=str)\n",
    "loss = lines[:,4].astype('float')\n",
    "train_loss = loss[::2]\n",
    "val_loss = loss[1::2]\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.savefig(f'Outputs/{savedir}/loss.png')\n",
    "plt.show()\n",
    "\n",
    "accseg = lines[:,7].astype('float')\n",
    "train_accseg = accseg[::2]\n",
    "val_accseg = accseg[1::2]\n",
    "plt.plot(train_accseg)\n",
    "plt.plot(val_accseg)\n",
    "plt.savefig(f'Outputs/{savedir}/seg_acc.png')\n",
    "plt.show()\n",
    "\n",
    "accclass = lines[:,10].astype('float')\n",
    "train_accclass = accclass[::2]\n",
    "val_accclass = accclass[1::2]\n",
    "plt.plot(train_accclass)\n",
    "plt.plot(val_accclass)\n",
    "plt.savefig(f'Outputs/{savedir}/class_Acc.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7108f1ef",
   "metadata": {},
   "source": [
    "## Check the number of trainable parameters in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(f'Number of trainable parameters in the model : {pytorch_total_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1946571c",
   "metadata": {},
   "source": [
    "## Create some plots to analyse the models segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84127d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 1\n",
    "break_idx = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0432bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(testloader):\n",
    "    inputs, segs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    segs = segs.to(device)\n",
    "    labels = labels.to(device)-1\n",
    "    segs_labelled = torch.mul(segs, labels.view(-1,1,1))\n",
    "    \n",
    "    outputs, out_class = net(inputs)\n",
    "\n",
    "    inputs_rot = torch.rot90(inputs, k=1, dims=[-2,-1])\n",
    "    segs_rot = torch.rot90(segs, k=1, dims=[-2,-1])\n",
    "    \n",
    "    outputs_rot, out_class_rot = net(inputs_rot)\n",
    "    \n",
    "    if i == break_idx:\n",
    "        break\n",
    "        \n",
    "outputs = torch.sigmoid(outputs)\n",
    "outputs[outputs>=0.5] = 1\n",
    "outputs[outputs<0.5] = 0\n",
    "outputs = torch.squeeze(outputs, dim=1).detach().cpu().numpy()\n",
    "\n",
    "outputs_rot = torch.sigmoid(outputs_rot)\n",
    "outputs_rot[outputs_rot>=0.5] = 1\n",
    "outputs_rot[outputs_rot<0.5] = 0\n",
    "outputs_rot = torch.squeeze(outputs_rot, dim=1).detach().cpu().numpy()\n",
    "\n",
    "inputs = inputs.detach().cpu().numpy()\n",
    "inputs_rot = inputs_rot.detach().cpu().numpy()\n",
    "out_class = out_class.detach().cpu().numpy()\n",
    "out_class_rot = out_class_rot.detach().cpu().numpy()\n",
    "segs = segs.detach().cpu().numpy()\n",
    "segs_rot = segs_rot.detach().cpu().numpy()\n",
    "segs_labelled = segs_labelled.detach().cpu().numpy()\n",
    "labels = labels.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a7826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Predicted label {np.argmax(out_class[img_idx])} - True label {labels[img_idx]}')\n",
    "print(f'Predicted label {np.argmax(out_class_rot[img_idx])} - True label {labels[img_idx]}')\n",
    "plt.figure(figsize=(21,14))\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(np.transpose(inputs[img_idx].astype(int)+100, (1,2,0)))\n",
    "plt.title(f'Original Image')\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(np.transpose(inputs[img_idx].astype(int)+100, (1,2,0)))\n",
    "segs_plot = np.repeat(np.expand_dims(segs[img_idx], axis=2), 4, axis=2)\n",
    "segs_plot[:,:,0][segs_plot[:,:,0]==1] = 220\n",
    "segs_plot[:,:,1][segs_plot[:,:,1]==1] = 50\n",
    "segs_plot[:,:,2][segs_plot[:,:,2]==1] = 32\n",
    "segs_plot[:,:,3][segs_plot[:,:,3]==1] = 200\n",
    "plt.imshow(segs_plot)\n",
    "plt.title(f'Original Image with Segmentation Map')\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(np.transpose(inputs[img_idx].astype(int)+100, (1,2,0)))\n",
    "outputs_plot = np.repeat(np.expand_dims(outputs[img_idx], axis=2), 4, axis=2)\n",
    "outputs_plot = outputs_plot.astype(int)\n",
    "outputs_plot[:,:,0][outputs_plot[:,:,0]==1] = 0\n",
    "outputs_plot[:,:,1][outputs_plot[:,:,1]==1] = 90\n",
    "outputs_plot[:,:,2][outputs_plot[:,:,2]==1] = 181\n",
    "outputs_plot[:,:,3][outputs_plot[:,:,3]==1] = 255\n",
    "im = plt.imshow(outputs_plot)\n",
    "plt.imshow(edge_sobel_segs)\n",
    "plt.title(f'Original Segmentation Prediction')\n",
    "\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.imshow(np.transpose(inputs_rot[img_idx].astype(int)+100, (1,2,0)))\n",
    "plt.title(f'Image Rotated 90deg')\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(np.transpose(inputs_rot[img_idx].astype(int)+100, (1,2,0)))\n",
    "segs_rot_plot = np.repeat(np.expand_dims(segs_rot[img_idx], axis=2), 4, axis=2)\n",
    "segs_rot_plot[:,:,0][segs_rot_plot[:,:,0]==1] = 220\n",
    "segs_rot_plot[:,:,1][segs_rot_plot[:,:,1]==1] = 50\n",
    "segs_rot_plot[:,:,2][segs_rot_plot[:,:,2]==1] = 32\n",
    "segs_rot_plot[:,:,3][segs_rot_plot[:,:,3]==1] = 200\n",
    "plt.imshow(segs_rot_plot)\n",
    "plt.title(f'Original Image with Segmentation Map Rotated 90deg')\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "plt.imshow(np.transpose(inputs[img_idx].astype(int)+100, (1,2,0)))\n",
    "outputs_rot_plot = np.repeat(np.expand_dims(outputs_rot[img_idx], axis=2), 4, axis=2)\n",
    "outputs_rot_plot = outputs_rot_plot.astype(int)\n",
    "outputs_rot_plot[:,:,0][outputs_rot_plot[:,:,0]==1] = 0\n",
    "outputs_rot_plot[:,:,1][outputs_rot_plot[:,:,1]==1] = 90\n",
    "outputs_rot_plot[:,:,2][outputs_rot_plot[:,:,2]==1] = 181\n",
    "outputs_rot_plot[:,:,3][outputs_rot_plot[:,:,3]==1] = 255\n",
    "im = plt.imshow(outputs_rot_plot)\n",
    "plt.imshow(edge_sobel_segs_rot)\n",
    "\n",
    "plt.title(f'Segmentation Prediction with Rotated 90deg Image')\n",
    "# plt.tight_layout()\n",
    "plt.savefig(f'Outputs/{savedir}/seg_{break_idx}_{img_idx}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3fa918",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.transpose(inputs[img_idx].astype(int)+100, (1,2,0)))\n",
    "plt.axis('off')\n",
    "plt.savefig(f'Outputs/{savedir}/seg_{break_idx}_{img_idx}_orig_img.png', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.transpose(inputs[img_idx].astype(int)+100, (1,2,0)))\n",
    "plt.imshow(segs[img_idx], cmap='Greys', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.savefig(f'Outputs/{savedir}/seg_{break_idx}_{img_idx}_orig_img_orig_seg.png', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.transpose(inputs[img_idx].astype(int)+100, (1,2,0)))\n",
    "outputs_plot = np.repeat(np.expand_dims(outputs[img_idx], axis=2), 4, axis=2)\n",
    "outputs_plot = outputs_plot.astype(int)\n",
    "outputs_plot[:,:,0][outputs_plot[:,:,0]==1] = 136\n",
    "outputs_plot[:,:,1][outputs_plot[:,:,1]==1] = 204\n",
    "outputs_plot[:,:,2][outputs_plot[:,:,2]==1] = 238\n",
    "outputs_plot[:,:,3][outputs_plot[:,:,3]==1] = 255\n",
    "im = plt.imshow(outputs_plot)\n",
    "plt.imshow(edge_sobel_segs)\n",
    "plt.axis('off')\n",
    "plt.savefig(f'Outputs/{savedir}/seg_{break_idx}_{img_idx}_orig_img_pred_seg_v2.png', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.transpose(inputs_rot[img_idx].astype(int)+100, (1,2,0)))\n",
    "plt.axis('off')\n",
    "plt.savefig(f'Outputs/{savedir}/seg_{break_idx}_{img_idx}_rot_img.png', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.transpose(inputs_rot[img_idx].astype(int)+100, (1,2,0)))\n",
    "plt.imshow(segs_rot[img_idx], cmap='Greys', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.savefig(f'Outputs/{savedir}/seg_{break_idx}_{img_idx}_rot_img_orig_seg.png', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.transpose(inputs[img_idx].astype(int)+100, (1,2,0)))\n",
    "outputs_rot_plot = np.repeat(np.expand_dims(outputs_rot[img_idx], axis=2), 4, axis=2)\n",
    "outputs_rot_plot = outputs_rot_plot.astype(int)\n",
    "outputs_rot_plot[:,:,0][outputs_rot_plot[:,:,0]==1] = 136\n",
    "outputs_rot_plot[:,:,1][outputs_rot_plot[:,:,1]==1] = 204\n",
    "outputs_rot_plot[:,:,2][outputs_rot_plot[:,:,2]==1] = 238\n",
    "outputs_rot_plot[:,:,3][outputs_rot_plot[:,:,3]==1] = 255\n",
    "im = plt.imshow(outputs_rot_plot)\n",
    "plt.imshow(edge_sobel_segs_rot)\n",
    "plt.axis('off')\n",
    "plt.savefig(f'Outputs/{savedir}/seg_{break_idx}_{img_idx}_rot_img_pred_seg_v2.png', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69830b15",
   "metadata": {},
   "source": [
    "## Print classification accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad57b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_class = 0.0\n",
    "for i, data in enumerate(trainloader):\n",
    "    inputs, segs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    segs = segs.to(device)\n",
    "    labels = labels.to(device)-1\n",
    "    segs_labelled = torch.mul(segs, labels.view(-1,1,1))\n",
    "\n",
    "    outputs, out_class = net(inputs)\n",
    "    \n",
    "    running_acc_class += get_acc_class(out_class, labels).item()\n",
    "    \n",
    "print(f'Train Classification Accuracy {running_acc_class/len(trainloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133be78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_class = 0.0\n",
    "for i, data in enumerate(valloader):\n",
    "    inputs, segs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    segs = segs.to(device)\n",
    "    labels = labels.to(device)-1\n",
    "    segs_labelled = torch.mul(segs, labels.view(-1,1,1))\n",
    "\n",
    "    outputs, out_class = net(inputs)\n",
    "    \n",
    "    running_acc_class += get_acc_class(out_class, labels).item()\n",
    "    \n",
    "print(f'Validation Classification Accuracy {running_acc_class/len(valloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff4349",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_class = 0.0\n",
    "for i, data in enumerate(testloader):\n",
    "    inputs, segs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    segs = segs.to(device)\n",
    "    labels = labels.to(device)-1\n",
    "    segs_labelled = torch.mul(segs, labels.view(-1,1,1))\n",
    "\n",
    "    outputs, out_class = net(inputs)\n",
    "    \n",
    "    running_acc_class += get_acc_class(out_class, labels).item()\n",
    "    \n",
    "print(f'Test Classification Accuracy {running_acc_class/len(testloader)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d0d8e",
   "metadata": {},
   "source": [
    "### Test classification accuracy with rotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b84f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_class = 0.0\n",
    "for i, data in enumerate(testloader):\n",
    "    inputs, segs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    segs = segs.to(device)\n",
    "    labels = labels.to(device)-1\n",
    "    segs_labelled = torch.mul(segs, labels.view(-1,1,1))\n",
    "\n",
    "    inputs_rot = torch.rot90(inputs, k=1, dims=[-2,-1])\n",
    "    segs_rot = torch.rot90(segs, k=1, dims=[-2,-1])\n",
    "\n",
    "    outputs, out_class = net(inputs_rot)\n",
    "    \n",
    "    running_acc_class += get_acc_class(out_class, labels).item()\n",
    "    \n",
    "print(f'Test Classification Accuracy {running_acc_class/len(testloader)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307e2900",
   "metadata": {},
   "source": [
    "## Print segmentation accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5cca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_mean = 0.0\n",
    "running_acc_mean_1 = 0.0\n",
    "running_acc_mean_0 = 0.0\n",
    "for i, data in enumerate(trainloader):\n",
    "    inputs, segs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    segs = segs.to(device)\n",
    "    labels = labels.to(device)-1\n",
    "    segs_labelled = torch.mul(segs, labels.view(-1,1,1))\n",
    "\n",
    "    outputs, out_class = net(inputs)\n",
    "    \n",
    "    m1, m0, m_avg = get_acc_binseg(outputs, torch.unsqueeze(segs.float(), dim=1))\n",
    "    running_acc_mean += m_avg.item()\n",
    "    running_acc_mean_1 += m1.item()\n",
    "    running_acc_mean_0 += m0.item()\n",
    "    \n",
    "print(f'Train Seg Accuracy Mean {running_acc_mean/len(trainloader)}')\n",
    "print(f'Train Seg Accuracy Mean 1s {running_acc_mean_1/len(trainloader)}')\n",
    "print(f'Train Seg Accuracy Mean 0s {running_acc_mean_0/len(trainloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_mean = 0.0\n",
    "running_acc_mean_1 = 0.0\n",
    "running_acc_mean_0 = 0.0\n",
    "for i, data in enumerate(valloader):\n",
    "    inputs, segs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    segs = segs.to(device)\n",
    "    labels = labels.to(device)-1\n",
    "    segs_labelled = torch.mul(segs, labels.view(-1,1,1))\n",
    "\n",
    "    outputs, out_class = net(inputs)\n",
    "    \n",
    "    m1, m0, m_avg = get_acc_binseg(outputs, torch.unsqueeze(segs.float(), dim=1))\n",
    "    running_acc_mean += m_avg.item()\n",
    "    running_acc_mean_1 += m1.item()\n",
    "    running_acc_mean_0 += m0.item()\n",
    "    \n",
    "print(f'Val Seg Accuracy Mean {running_acc_mean/len(valloader)}')\n",
    "print(f'Val Seg Accuracy Mean 1s {running_acc_mean_1/len(valloader)}')\n",
    "print(f'Val Seg Accuracy Mean 0s {running_acc_mean_0/len(valloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717fe760",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_mean = 0.0\n",
    "running_acc_mean_1 = 0.0\n",
    "running_acc_mean_0 = 0.0\n",
    "for i, data in enumerate(testloader):\n",
    "    inputs, segs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    segs = segs.to(device)\n",
    "    labels = labels.to(device)-1\n",
    "    segs_labelled = torch.mul(segs, labels.view(-1,1,1))\n",
    "\n",
    "    outputs, out_class = net(inputs)\n",
    "    \n",
    "    m1, m0, m_avg = get_acc_binseg(outputs, torch.unsqueeze(segs.float(), dim=1))\n",
    "    running_acc_mean += m_avg.item()\n",
    "    running_acc_mean_1 += m1.item()\n",
    "    running_acc_mean_0 += m0.item()\n",
    "    \n",
    "print(f'Test Seg Accuracy Mean {running_acc_mean/len(testloader)}')\n",
    "print(f'Test Seg Accuracy Mean 1s {running_acc_mean_1/len(testloader)}')\n",
    "print(f'Test Seg Accuracy Mean 0s {running_acc_mean_0/len(testloader)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399933b3",
   "metadata": {},
   "source": [
    "### Segmentation accuracy with rotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f98ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_mean = 0.0\n",
    "running_acc_mean_1 = 0.0\n",
    "running_acc_mean_0 = 0.0\n",
    "for i, data in enumerate(testloader):\n",
    "    inputs, segs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    segs = segs.to(device)\n",
    "    labels = labels.to(device)-1\n",
    "    segs_labelled = torch.mul(segs, labels.view(-1,1,1))\n",
    "    \n",
    "    inputs_rot = torch.rot90(inputs, k=1, dims=[-2,-1])\n",
    "    segs_rot = torch.rot90(segs, k=1, dims=[-2,-1])\n",
    "\n",
    "    outputs, out_class = net(inputs_rot)\n",
    "    \n",
    "    m1, m0, m_avg = get_acc_binseg(outputs, torch.unsqueeze(segs_rot.float(), dim=1))\n",
    "    running_acc_mean += m_avg.item()\n",
    "    running_acc_mean_1 += m1.item()\n",
    "    running_acc_mean_0 += m0.item()\n",
    "    \n",
    "print(f'Test Seg Accuracy Mean {running_acc_mean/len(testloader)}')\n",
    "print(f'Test Seg Accuracy Mean 1s {running_acc_mean_1/len(testloader)}')\n",
    "print(f'Test Seg Accuracy Mean 0s {running_acc_mean_0/len(testloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_mean = 0.0\n",
    "running_acc_mean_1 = 0.0\n",
    "running_acc_mean_0 = 0.0\n",
    "for i, data in enumerate(testloader):\n",
    "    inputs, segs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    segs = segs.to(device)\n",
    "    labels = labels.to(device)-1\n",
    "    segs_labelled = torch.mul(segs, labels.view(-1,1,1))\n",
    "    \n",
    "    inputs_rot = torch.rot90(inputs, k=2, dims=[-2,-1])\n",
    "    segs_rot = torch.rot90(segs, k=2, dims=[-2,-1])\n",
    "\n",
    "    outputs, out_class = net(inputs_rot)\n",
    "    \n",
    "    m1, m0, m_avg = get_acc_binseg(outputs, torch.unsqueeze(segs_rot.float(), dim=1))\n",
    "    running_acc_mean += m_avg.item()\n",
    "    running_acc_mean_1 += m1.item()\n",
    "    running_acc_mean_0 += m0.item()\n",
    "    \n",
    "print(f'Test Seg Accuracy Mean {running_acc_mean/len(testloader)}')\n",
    "print(f'Test Seg Accuracy Mean 1s {running_acc_mean_1/len(testloader)}')\n",
    "print(f'Test Seg Accuracy Mean 0s {running_acc_mean_0/len(testloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ba6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_mean = 0.0\n",
    "running_acc_mean_1 = 0.0\n",
    "running_acc_mean_0 = 0.0\n",
    "for i, data in enumerate(testloader):\n",
    "    inputs, segs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    segs = segs.to(device)\n",
    "    labels = labels.to(device)-1\n",
    "    segs_labelled = torch.mul(segs, labels.view(-1,1,1))\n",
    "    \n",
    "    inputs_rot = torch.rot90(inputs, k=3, dims=[-2,-1])\n",
    "    segs_rot = torch.rot90(segs, k=3, dims=[-2,-1])\n",
    "\n",
    "    outputs, out_class = net(inputs_rot)\n",
    "    \n",
    "    m1, m0, m_avg = get_acc_binseg(outputs, torch.unsqueeze(segs_rot.float(), dim=1))\n",
    "    running_acc_mean += m_avg.item()\n",
    "    running_acc_mean_1 += m1.item()\n",
    "    running_acc_mean_0 += m0.item()\n",
    "    \n",
    "print(f'Test Seg Accuracy Mean {running_acc_mean/len(testloader)}')\n",
    "print(f'Test Seg Accuracy Mean 1s {running_acc_mean_1/len(testloader)}')\n",
    "print(f'Test Seg Accuracy Mean 0s {running_acc_mean_0/len(testloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7917c57a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:e2cnn] *",
   "language": "python",
   "name": "conda-env-e2cnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
